{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning with Non-Ignorable Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Christine Hwang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChrsitineHwang/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
    "from sklearn.linear_model import Ridge as Ridge_Reg\n",
    "from sklearn.linear_model import Lasso as Lasso_Reg\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import sklearn.preprocessing as Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler as Standardize\n",
    "import itertools as it\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import scipy as sp\n",
    "from itertools import combinations\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "Missing data is defined to be non-ignorable if it is not missing at random. Non-ignorable missing data causes the inference based on observed data to lead to biased parameter estimates and can affect the significance of your results. This paper attempts to use probabilistic models to fill in missing data to reduce this bias\n",
    "\n",
    "### Example\n",
    "In the scenario where you have netflix movie ratings, you are more likely to rate movies that you really enjoy or really dislike, but rarely rate movies that you are neutral about. Therefore, most of the missing data tends to be from these middle ratings and the distribution of the observed data is shifted to the right from the true distribution of copmletely filled data. In this scenario, the probability of observing a particular response depends on the value itself. Therefore, ignoring missing data can lead to biased parameter estimates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Mixture Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GraphicalModel.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This standard mixsture model shows a latent variable z behind each observation Y. In this example of a multinomial mixture model, $z_n$ represents the latent variable behind each entry which is pulled from a $\\theta_k$ prior. This means that there are k different latent variables that our multinomial distribution can come from. For each observed value given its latent variable, there is a $\\beta_{vmz}$ that represents the probability of any observation taking a specific value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just want to make sure I have the right interpretation of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the scenario where we represent the netflix movie ratings as a multinomial distribution. Then from the diagram above, $Y_{1n'}$ = the rating star count for movie 1 for person n' and we assume there are n # people. Then if $Y_{im}$ = v, that means that the star count for movie i from person m = v. To represent each $Y_m$ is a multinomial distribution, we will define it as Mult($\\theta_j$, M), where $\\theta_z$ = P(selecting word v from latent variable z) where M is the total number of ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z_n$ ~ Mult($\\pi$,1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pi$ = [.3, .2, .1, .4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the probability of having a latent variable $z_1$ = .3, $z_2$ = .2, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we represent each $Y_{m}|z_i$ ~ Multi($\\theta_z$,N), we view $\\theta_z$ to be the probability distribution of ratings for a single movie. For example, $\\theta = [.1 .2 .7]$ means that the probability you give the movie 1 star is .1, probability you give it 2 stars is .2, and probability you give it three stars is .7, and you can set your M = N so that it follows a Multinomial($\\theta$, N). This is because N people give movie $m$ a rating and therefore the distribution of all the ratings that the N people could have given movie $m$ is Multinoimal given the $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the $\\beta$ estimates $\\theta$ is if we view $\\theta$ to be the probability distribution of ratings for a single movie. For example, $\\theta = [.1 .2 .7]$ means that the probability you give the movie 1 star is .1, probability you give it 2 stars is .2, and probability you give it three stars is .7, and you can set your M = N so that it follows a Multinomial($\\theta$, N). Then it would make sense that $Y_{m}$~Multi($\\beta$,N) which represents the ratings from N people for the $m^{th}$ movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPT-v Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Model2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extrapolate from the previous model to show the missing data. $\\mu_v$ = $P(R_m = 1 | Y_m = v)$, whic his the probability the value is missing given the true value of the data. In our movie rating example, this probability is higher is $Y_m = 2-3$ because we are less likely to see a rating for a mediocre movie. Need to clarify previous questions before analyzing this model further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope to apply this model of missing data to medical data. For example, in data analyzing blood pressure or cholesterol, we may see that the probability of seeing missing values for younger, healthier people is higher than for older people because they are less likely to have health complications that require these measurements. Doctors may assume that these measurements are not necessary for the checkup and therefore the data will not be missing at random. In order to use this probabilistic model to fill in missing values, I need to understanding how these categorical variables (if you just convert them to integers) can represent a multinomial distribution. If a person's blood pressure can take the values [10, 50, 100], and our $\\theta = [.2 .2 .6]$, does this mean that the person's blood pressure = Multinomial($\\theta$, 1)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"EM.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\phi_{zn}$ = posterior distribution of the latent variable z "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta_z$ = probability of that latent variable Z = z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\beta_{vmz}$ = probability that Y = v given latent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mu_v$ = probability that $Y_i$ is missing given is has value v."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\gamma$ and $\\lambda$ are intermediate variables without interpretable value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\delta = I(y_{mn} = v)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$u_v$ comes from a beta distribution because it is a prior for a Binomial Distribution\n",
    "\n",
    "$\\theta$ comes from a Dirichlet distribution\n",
    "\n",
    "$\\beta$ comes from a dirichlet distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [[5, 3, 4, 2, 3, 1], [1,4,3,5,1,2],[5,2,3,1,4,3], [4,3,5,5,4,2]]\n",
    "###########\n",
    "# y = [5 4 3 2 3 1]\n",
    "#     [1 4 3 5 1 2]\n",
    "#     [5 2 3 1 4 3]\n",
    "#     [4 3 5 5 4 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = [[1,1,0,0,1,1],[1,1,0,1,0,1],[1,0,0,0,1,0],[1,1,1,1,0,0]]\n",
    "########\n",
    "# r = [1 1 0 0 1 1]\n",
    "#     [1 1 0 1 0 1]\n",
    "#     [1 0 0 0 1 0]\n",
    "#     [1 1 1 1 0 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Full Data\n",
    "I created the probability distribution of movies for there different movies. Movie 1 is a bad movie that is likely to get a lot of 1s. Beta 2 is just an average movie whose ratings will resemble a normal distribution centered at 3. Movie 3 is a great movie that is likely to get very high reviews. Concatentate these ratings to get your full data set of 100 movie ratings for these 3 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize dimensions\n",
    "z = 2\n",
    "n = 100\n",
    "m = 3\n",
    "v = 5\n",
    "#bad movie. high probability of getting 1s and low prob of getting 5\n",
    "beta_1 = [.5,.2,.1,.1,.1]\n",
    "#average movie. \n",
    "beta_2 = [.1,.2,.5,.2,.1]\n",
    "#great movie\n",
    "beta_3 = [.05,.1,.1,.35,.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_1_freq = np.random.multinomial(n, beta_1)\n",
    "y_2_freq = np.random.multinomial(n,beta_2)\n",
    "y_3_freq = np.random.multinomial(n,beta_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_1 = []\n",
    "y_2 = []\n",
    "y_3 = []\n",
    "for i in range(v):\n",
    "    y_1 += [i+1]*y_1_freq[i]\n",
    "    y_2 += [i+1]*y_2_freq[i]\n",
    "    y_3 += [i+1]*y_3_freq[i]\n",
    "complete_data = np.vstack((y_1,y_2,y_3)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mu Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper in study, we let $\\mu_v(s)$ = $s$($v$ − 3) + 0.5, where $s$ is the parameter that controls the strength of the effect. I will set $s$ = .075. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.275,  0.35 ,  0.425,  0.5  ,  0.575])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = np.ones(v)\n",
    "for i in range(v):\n",
    "    mu[i] = .075*(i-3)+.5\n",
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of the example of a movie rating, It makes more sense that the movie will be missing reviews it is a neutral movie than a bad movie. Therefore, I reversed the probability so that it more resembles a bell shaped distribution where the probability of the rating being missing peaks when star = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35 ,  0.425,  0.5  ,  0.425,  0.35 ])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(v):\n",
    "    mu[i] = -.075*abs(i-2)+.5\n",
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern for Missing Data (R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this, we want to create a matrix that indicates 1 if the data is observed and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.ones((n,m))\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n_ in range(n):\n",
    "    for m_ in range(m):\n",
    "        val = complete_data[n_][m_]\n",
    "        if np.random.rand(1) < mu[val-1]:\n",
    "            r[n_][m_] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull $\\theta, \\beta$ from Dirichlet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because $\\theta$ and $\\beta$ are good priors for categorical distribution and multinomial distributions, they are appropriate priors for $\\theta$ and $\\beta$ because both represent the probability of taking a specific categorical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# theta = np.zeros((1,z))\n",
    "# beta = np.zeros((v,m,z))\n",
    "theta = np.random.dirichlet((1,1),1)\n",
    "beta = np.random.dirichlet((1,1,1,1,1),(2,3)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi = np.ones((z,n))\n",
    "gamma = np.ones((m,z,n))\n",
    "lambda_ = np.ones((v,m,z,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):   \n",
    "    \n",
    "    ### E step\n",
    "    \n",
    "    ###### lambda\n",
    "    for v_ in range(v):\n",
    "        for m_ in range(m):\n",
    "            for z_ in range(z):\n",
    "                for n_ in range(n):\n",
    "                    lambda_[v_][m_][z_][n_] = ((1)*mu[v_]*beta[v_][m_][z_])**r[n_][m_]*((1-mu[v_])*beta[v_][m_][z_])**(1-r[n_][m_])\n",
    "\n",
    "\n",
    "    ###### gamma\n",
    "    gamma = lambda_.sum(axis = 0)\n",
    "\n",
    "    ###### phi\n",
    "    phi = np.tile(theta, (n,1)).T*gamma.prod(axis = 0)/(np.tile(theta, (n,1)).T*gamma.prod(axis = 0)).sum(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    ### M step\n",
    "\n",
    "    theta = phi.sum(axis=1)/phi.sum()\n",
    "    theta_rep = np.tile(theta, (z,1))\n",
    "\n",
    "    ####beta\n",
    "    sum_phi = 0 \n",
    "    for v_ in range(v):\n",
    "        for m_ in range(m):\n",
    "            for z_ in range(z):\n",
    "                sum_ = 0\n",
    "                for n_ in range(n):\n",
    "                    sum_ =+ phi[z_][n_]*lambda_[v_][m_][z_][n_]/gamma[m_][z_][n_]\n",
    "                    sum_phi += phi[z_][n_]\n",
    "                beta[v_][m_][z_] = sum_/sum_phi\n",
    "    ######mu\n",
    "    for v_ in range(v):\n",
    "        num = 0\n",
    "        denom = 0\n",
    "        for n_ in range(n):\n",
    "            for z_ in range(z):\n",
    "                for m_ in range(m):\n",
    "                    num += phi[z_][n_]*r[n_][m_]*lambda_[v_][m_][z_][n_]/gamma[m_][z_][n_]\n",
    "                    denom += phi[z_][n_]*lambda_[v_][m_][z_][n_]/gamma[m_][z_][n_]\n",
    "        mu[v_] = num/denom\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  9.94603591e-003,   7.99282665e-209],\n",
       "        [  2.92564278e-003,   3.56717512e-209],\n",
       "        [  3.19688682e-003,   2.23504825e-209]],\n",
       "\n",
       "       [[  1.26647268e-005,   1.16401454e-210],\n",
       "        [  6.35883962e-004,   1.89298822e-210],\n",
       "        [  5.64339768e-005,   2.60309358e-210]],\n",
       "\n",
       "       [[  3.68826110e-007,   3.85155376e-213],\n",
       "        [  1.13787094e-004,   4.50706167e-211],\n",
       "        [  3.89324583e-006,   1.30216315e-211]],\n",
       "\n",
       "       [[  5.27011638e-009,   3.93720491e-213],\n",
       "        [  5.00436304e-006,   1.22032914e-212],\n",
       "        [  2.12811310e-006,   1.36544897e-213]],\n",
       "\n",
       "       [[  5.15924643e-008,   1.30434068e-213],\n",
       "        [  2.82134050e-007,   8.52035631e-213],\n",
       "        [  6.77274577e-007,   5.39515226e-212]]])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to hard code with for loop for three of the predictors. Working on how to use matrix multiplication but can't see a clear pattern. Also not sure how to use $\\beta$ to actually predict the values after the fitting is done. Do I call np.random.multinomial($\\beta$, 1) then take the index of the array that has 1 success and fill in that missing value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,   2.,   2.,   2.,   2.],\n",
       "       [  4.,   4.,   4.,   4.,   4.],\n",
       "       [  6.,   6.,   6.,   6.,   6.],\n",
       "       [  8.,   8.,   8.,   8.,   8.],\n",
       "       [ 10.,  10.,  10.,  10.,  10.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(theta, (z,1)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Links\n",
    "\n",
    "Description of Multinomial Mixture Models\n",
    "http://web.stanford.edu/~lmackey/stats306b/doc/stats306b-spring14-lecture3_scribed.pdf\n",
    "https://www.cs.princeton.edu/courses/archive/spring12/cos424/pdf/em-mixtures.pdf\n",
    "\n",
    "My specific Paper\n",
    "http://www.cs.ubc.ca/~bmarlin/research/presentations/lnimd_group_talk.pdf\n",
    "https://people.cs.umass.edu/~marlin/research/papers/aistat-lnimd.pdf\n",
    "\n",
    "Application of my paper\n",
    "http://ijcai.org/Proceedings/11/Papers/447.pdf\n",
    "http://www.cs.toronto.edu/~zemel/documents/cfmar-uai2007.pdf\n",
    "https://pdfs.semanticscholar.org/2845/eda7ce8de14e351d41182f92b73ece8873ef.pdf\n",
    "https://people.cs.umass.edu/~marlin/research/thesis/cfmlp.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
